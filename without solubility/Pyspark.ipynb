{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf2dd5a5-6695-4b31-8f8f-5dd0534e2c74",
   "metadata": {},
   "source": [
    "# Using PySpark to predic if a compound is ab active inhibitor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d8f6f5-f6fa-4795-b07e-d085ec7dfd0f",
   "metadata": {},
   "source": [
    "\n",
    "This notebook is avaliable on Google Colab\n",
    "https://colab.research.google.com/drive/11lfOdUjGPZ4jMcPjkbwCb512sRpwpyo8?usp=sharing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcfb5f0-1c9f-4113-8902-b4e0b65b04e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0971b216-8bb8-4acf-8e9c-9651940ee37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b279a26-d715-40ed-a629-1f3b00d728e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/content/drive/MyDrive/data_classification_smote.csv', index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d4d8d6-c73b-4c24-b5c9-6cefcdbd1517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1555acec-3491-41bf-b96e-b36a0a3ab3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('G9a_clsf').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6c8d7e-772c-4682-a256-25d7d02ae13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568aff7c-073f-4a18-b1ba-6f5dd7d6c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option('header','true').csv('/content/drive/MyDrive/data_classification_smote.csv', inferSchema=True)\n",
    "df_pyspark = df_pyspark.drop('_c0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8825b2db-c407-470f-b513-232754551883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a3bb54-bae2-4f2f-b477-329aa7e1c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dd944d-7650-439c-a398-bf31b46b8ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g9a=spark.read \\\n",
    "      .option(\"header\",\"True\")\\\n",
    "      .option(\"inferSchema\",\"True\")\\\n",
    "      .option(\"sep\",\",\")\\\n",
    "      .csv('/content/drive/MyDrive/data_classification_smote_noSolub.csv')\n",
    "\n",
    "df_g9a = df_g9a.drop('_c0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41555fd7-ff3a-4757-be2b-9d6c0760d94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are\", df_g9a.count(),\n",
    "      \"rows\", len(df_g9a.columns),\n",
    "      \"columns in the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fa7786-051f-443b-bd06-95cd6f6a4170",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature = 'target'\n",
    "indep_features = [col for col in df_g9a.columns if col not in [target_feature]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6556e90-039e-4315-879d-6c9acc943785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af06133f-30ee-4fd8-b59c-8b8a186fd78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty stages list for pipeline\n",
    "stages_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d44caa-11b1-4d90-b7a4-e7bcb0855695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble features into a vector\n",
    "assembler = VectorAssembler(inputCols=indep_features, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cd9f24-58f8-4495-9810-e1b2b4aa985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update stages list\n",
    "stages_list += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f36231-36f5-4f13-ac36-317e4b396b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with the assembler and other transformations\n",
    "pipeline = Pipeline(stages=stages_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7ef45f-c220-4cb4-a3a6-997fef637d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline on the training data\n",
    "df_pipeline= pipeline.fit(df_g9a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f62e558-8dd4-412d-94ea-e6b7a4deee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training data\n",
    "df_g9a_transformed = df_pipeline.transform(df_g9a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b09d5c-420d-4bf2-b6e3-fc963c659330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the transformed data into training and testing sets\n",
    "train_data, test_data = df_g9a_transformed.randomSplit([0.8, 0.2], seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51dd096-1133-4e34-ace4-47550f2a2d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f28134-0e3c-4f14-875a-a14024349ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest Classifier model\n",
    "rfc = RandomForestClassifier(featuresCol=\"features\", labelCol=target_feature, numTrees=3, maxDepth=2)\\\n",
    "    .fit(train_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rfc_predictions = rfc.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc809d9-1946-4b25-98c8-ad6eb1360cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=target_feature)\n",
    "area_under_curve = evaluator.evaluate(rfc_predictions)\n",
    "print(f\"Area under ROC curve: {area_under_curve}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d3e669-238a-43cc-a900-956ef4f4e65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trainingSummary = rfc.summary\n",
    "lrROC = trainingSummary.roc.toPandas()\n",
    "\n",
    "plt.plot(lrROC['FPR'],lrROC['TPR'])\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.xlabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "print('Training set areaUnderROC: ' + str(trainingSummary.areaUnderROC))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04144f20-8a4f-4ba2-8a03-6966e9c0548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = trainingSummary.pr.toPandas()\n",
    "plt.plot(pr['recall'],pr['precision'])\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
